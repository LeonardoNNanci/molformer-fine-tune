{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "import optuna_integration\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.read_csv(\"../../data/ld50/train.csv\")[\"Class\"]\n",
    "Y_test = pd.read_csv(\"../../data/ld50/test.csv\")[\"Class\"]\n",
    "\n",
    "X_train = pd.read_csv(\"train_embeddings.csv\")\n",
    "X_test = pd.read_csv(\"test_embeddings.csv\")\n",
    "\n",
    "class_labels = [\"Alto\", \"Moderado\", \"Leve\", \"Desprezível\"][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "train_sample_weight = compute_sample_weight(class_weight='balanced', y=Y_train)\n",
    "valid_sample_weigth = compute_sample_weight(class_weight='balanced', y=Y_valid)\n",
    "test_sample_weight = compute_sample_weight(class_weight='balanced', y=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_eval_metric = float(\"inf\")\n",
    "\n",
    "def objective(trial):\n",
    "    global best_model\n",
    "    global best_eval_metric\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        verbosity=0,\n",
    "\n",
    "        objective= 'multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        n_estimators=5000,\n",
    "        num_class=len(Y_train.unique()),\n",
    "        \n",
    "        max_depth=trial.suggest_int('max_depth', 2, 6), \n",
    "        learning_rate=trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.5,\n",
    "        early_stopping_rounds=trial.suggest_int('early_stop', 10, 100),\n",
    "        callbacks=[optuna_integration.XGBoostPruningCallback(trial, 'validation_0-mlogloss')],\n",
    "\n",
    "        n_jobs=4\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              sample_weight=train_sample_weight,\n",
    "              eval_set=[(X_test, Y_test)], \n",
    "              sample_weight_eval_set=[valid_sample_weigth, test_sample_weight],\n",
    "              verbose=5000)\n",
    "\n",
    "    eval_metric = model.evals_result()['validation_0']['mlogloss'][-1]\n",
    "\n",
    "    if eval_metric < best_eval_metric:\n",
    "        best_eval_metric = eval_metric\n",
    "        best_model = model\n",
    "\n",
    "    return eval_metric\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                            storage=\"sqlite:///XGB_Tox_Pred.sqlite3\", \n",
    "                            study_name=f\"Classification{datetime.now().isoformat()}\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "bst.save_model(f\"xgboost_classfifcation_model_{datetime.now().isoformat()}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.XGBClassifier()\n",
    "bst.load_model(\"xgboost_classfifcation_model_2024-06-19T10:57:14.894608.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bst.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "matrix = np.zeros((4, 4), dtype=np.float64)\n",
    "for i, (p, t) in enumerate(zip(pred, Y_test)):\n",
    "    matrix[t, p] += 1\n",
    "\n",
    "annot = np.copy(matrix)\n",
    "for i, count in enumerate(Y_test.value_counts().sort_index()):\n",
    "    matrix[i] /= count\n",
    "\n",
    "sns.heatmap(matrix, cmap='coolwarm', robust=True, annot=annot, fmt='g', xticklabels=class_labels, yticklabels=class_labels).set_title(\"Matriz de confusão\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(classification_report(Y_test.values, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MoLFormer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
